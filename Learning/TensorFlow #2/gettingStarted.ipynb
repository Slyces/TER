{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3:  Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "sess.run(node3):  7.0\n"
     ]
    }
   ],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3: \", node3)\n",
    "print(\"sess.run(node3): \",sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: Tensor(\"Placeholder_2:0\", dtype=float32)\n",
      "b: Tensor(\"Placeholder_3:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Jusque là, rien de nouveau !\n",
    "# Ce graphe est assez boring, il dépend de constantes ...\n",
    "# Mais pas de panique !\n",
    "# C'est ici qu'entrent en jeu les <placeholder> :\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "# Ce sont des noeuds :\n",
    "print(\"a:\", a)\n",
    "print(\"b:\", b)\n",
    "# Et on peut créer des noeuds dépendant d'eux\n",
    "adder = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[  4.   5.   6.   7.   8.   9.  10.  11.]\n"
     ]
    }
   ],
   "source": [
    "# Ici, je découvre que alt + enter crée un nouveau noeud\n",
    "# tout en éxécutant, c'est génial !\n",
    "\n",
    "# Maintenant, si on veut éxécuter adder, on a besoin\n",
    "# de lui donner un dictionnaire de paramètres:\n",
    "print(sess.run(adder, feed_dict={\n",
    "    a: 3, b: 4.5\n",
    "}))\n",
    "print(sess.run(adder, feed_dict={\n",
    "    a: [i for i in range(8)], b: [4 for i in range(8)]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# On fait encore plus compliqué, #whaaaa\n",
    "triple = adder * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.5\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(triple, {a: 3, b:4.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# On attaque maintenant les noeuds dont le résultat varie\n",
    "# Ils utilisent ... wait for it ...\n",
    "# des Variables !\n",
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# /!\\ initialiser les variables !\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(linear_model, {x:[1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Bon, on a un modèle basique\n",
    "# Pour tester sa fiabilité, il nous faut un échantillon\n",
    "# comparatif de ce qu'on cherche à atteindre\n",
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ensuite, une fonction de calcul [vectoriel] de l'erreur\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "# On obtient un vecteur des erreurs locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Pour finir, on somme le vecteur.\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "# ici, reduce_sum veut dire que même dans le cas d'un\n",
    "# tensor de dimension > 1, on le réduit à un réel\n",
    "# (au vu des paramètres, tous à la valeur défault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "# Ici, on regarde l'erreur entre modele(x) et y\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.], dtype=float32), array([ 1.], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Les valeurs parfaites pour W & b sont resp. -1 & 1.\n",
    "# On pourrait les trouver manuellement, avec l'opération:\n",
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# What a guess, on a réussi à minimiser l'erreur au harsard,\n",
    "# On est trop forts !!§\n",
    "\n",
    "# Pour minimiser automatiquement, ça devient plus compliqué\n",
    "# tensorflow propose des <optimizers>\n",
    "# Le plus simple est la descente du gradient\n",
    "\n",
    "# Elle utilise la dérivée de la fonction d'erreur,\n",
    "# le gradient. Calculer la dérivée à la main étant\n",
    "# propice à erreurs, tensorflow peut le faire à notre\n",
    "# place lorsqu'on appelle l'<optimizer>\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess.run(init) # reset values to incorrect defaults.\n",
    "for i in range(1000):\n",
    "  sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "\n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "# Ci-dessus, les paramètres du modèle une fois qu'il a appris\n",
    "# On peut vérifier l'erreur, comparée au départ de 23.66 :\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nu5lZDjnczcxyyOFuZpZD/x/E5deAH2geCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2f0b869b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Très petit, non ?\n",
    "# Pour le fun, un petit graphing de l'erreur en utilisant\n",
    "# matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "sess.run(init) # reset values to incorrect defaults.\n",
    "losses = []\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "    losses.append(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))\n",
    "\n",
    "plt.plot([i for i in range(1000)], losses, 'k-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000106178\n"
     ]
    }
   ],
   "source": [
    "# Donc par exemple, les 400 premiers essais par exemple\n",
    "# semblent suffisant\n",
    "sess.run(init) # reset values to incorrect defaults.\n",
    "for i in range(400):\n",
    "  sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))\n",
    "# Déjà pas mal !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "# Code complet :\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "# training data\n",
    "x_train = [1,2,3,4]\n",
    "y_train = [0,-1,-2,-3]\n",
    "# training loop\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to wrong\n",
    "for i in range(1000):\n",
    "  sess.run(train, {x:x_train, y:y_train})\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss  = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpr77_wzom\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_task_type': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc2bf5c1b70>, '_tf_random_seed': None, '_is_chief': True, '_save_checkpoints_steps': None, '_master': '', '_environment': 'local', '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0}\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpr77_wzom/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.25\n",
      "INFO:tensorflow:global_step/sec: 1460.34\n",
      "INFO:tensorflow:step = 101, loss = 0.106567\n",
      "INFO:tensorflow:global_step/sec: 1214.56\n",
      "INFO:tensorflow:step = 201, loss = 0.00713813\n",
      "INFO:tensorflow:global_step/sec: 1414.71\n",
      "INFO:tensorflow:step = 301, loss = 0.00021467\n",
      "INFO:tensorflow:global_step/sec: 787.552\n",
      "INFO:tensorflow:step = 401, loss = 0.000205041\n",
      "INFO:tensorflow:global_step/sec: 853.67\n",
      "INFO:tensorflow:step = 501, loss = 5.6088e-05\n",
      "INFO:tensorflow:global_step/sec: 1139.44\n",
      "INFO:tensorflow:step = 601, loss = 1.41285e-05\n",
      "INFO:tensorflow:global_step/sec: 1479.38\n",
      "INFO:tensorflow:step = 701, loss = 3.03453e-06\n",
      "INFO:tensorflow:global_step/sec: 1710.61\n",
      "INFO:tensorflow:step = 801, loss = 1.50666e-07\n",
      "INFO:tensorflow:global_step/sec: 1642.39\n",
      "INFO:tensorflow:step = 901, loss = 1.8375e-08\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpr77_wzom/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.39644e-08.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-03-18-19:21:42\n",
      "INFO:tensorflow:Finished evaluation at 2017-03-18-19:21:42\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.16557e-08\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Maintenant, introduisons tf.contrib.learn pour simplifier\n",
    "# le code ci-dessus\n",
    "\n",
    "import tensorflow as tf\n",
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "\n",
    "# Declare list of features. We only have one real-valued feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# logistic regression, linear classification, logistic classification, and\n",
    "# many neural network classifiers and regressors. The following code\n",
    "# provides an estimator that does linear regression.\n",
    "estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use `numpy_input_fn`. We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x = np.array([1., 2., 3., 4.])\n",
    "y = np.array([0., -1., -2., -3.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x}, y, batch_size=4,\n",
    "                                              num_epochs=1000)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the `fit` method and passing the\n",
    "# training data set.\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did. In a real example, we would want\n",
    "# to use a separate validation and testing data set to avoid overfitting.\n",
    "estimator.evaluate(input_fn=input_fn)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpi1z0wwwz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_task_type': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc2ccc919e8>, '_tf_random_seed': None, '_is_chief': True, '_save_checkpoints_steps': None, '_master': '', '_environment': 'local', '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpi1z0wwwz/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 202.774145433\n",
      "INFO:tensorflow:global_step/sec: 1133.31\n",
      "INFO:tensorflow:step = 101, loss = 0.0942550942693\n",
      "INFO:tensorflow:global_step/sec: 1496.84\n",
      "INFO:tensorflow:step = 201, loss = 0.00865511556701\n",
      "INFO:tensorflow:global_step/sec: 1332.62\n",
      "INFO:tensorflow:step = 301, loss = 0.000528657305959\n",
      "INFO:tensorflow:global_step/sec: 1494.65\n",
      "INFO:tensorflow:step = 401, loss = 9.89927416909e-05\n",
      "INFO:tensorflow:global_step/sec: 1242.95\n",
      "INFO:tensorflow:step = 501, loss = 3.9850808762e-06\n",
      "INFO:tensorflow:global_step/sec: 1495.13\n",
      "INFO:tensorflow:step = 601, loss = 4.54868263613e-07\n",
      "INFO:tensorflow:global_step/sec: 1441.42\n",
      "INFO:tensorflow:step = 701, loss = 2.03160666259e-08\n",
      "INFO:tensorflow:global_step/sec: 1677.75\n",
      "INFO:tensorflow:step = 801, loss = 3.90285842088e-09\n",
      "INFO:tensorflow:global_step/sec: 1960.83\n",
      "INFO:tensorflow:step = 901, loss = 4.2144245726e-10\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpi1z0wwwz/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.40327562723e-11.\n",
      "INFO:tensorflow:Starting evaluation at 2017-03-18-19:42:33\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2017-03-18-19:42:33\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 3.54554e-11\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "{'loss': 3.5455382e-11, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Une nouvelle version qui mélange le low level tensorflow\n",
    "# et tf.contrib.learning\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model(features, labels, mode):\n",
    "  # Build a linear model and predict values\n",
    "  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "  y = W*features['x'] + b\n",
    "  # Loss sub-graph\n",
    "  loss = tf.reduce_sum(tf.square(y - labels))\n",
    "  # Training sub-graph\n",
    "  global_step = tf.train.get_global_step()\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "  train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "  # ModelFnOps connects subgraphs we built to the\n",
    "  # appropriate functionality.\n",
    "  return tf.contrib.learn.ModelFnOps(\n",
    "      mode=mode, predictions=y, loss=loss, train_op=train)\n",
    "\n",
    "estimator = tf.contrib.learn.Estimator(model_fn=model)\n",
    "# define our data set\n",
    "x = np.array([1., 2., 3., 4.])\n",
    "y = np.array([0., -1., -2., -3.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x}, y, 4, num_epochs=1000)\n",
    "\n",
    "# train\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "# evaluate our model\n",
    "print(estimator.evaluate(input_fn=input_fn, steps=10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

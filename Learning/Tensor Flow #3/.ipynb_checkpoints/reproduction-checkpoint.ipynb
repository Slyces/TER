{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf, numpy as np, pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Fonction d'initialisation des variables de poids\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Notre modèle sera, d'après l'article, sur une architecture 40 - 41 - 41 - 4\n",
    "# <inputs> - 40\n",
    "# <hidden> - 41\n",
    "# <hidden> - 41\n",
    "# <output> -  4\n",
    "def model(X, w_h1, w_h2, w_o, p_keep_input=1., p_keep_hidden=1.): \n",
    "    # =====================================================================================================\n",
    "    # X    : les inputs, shape [n x 40]\n",
    "    # w_h1 : les poids du premier hidden layer, shape [40 x 41]\n",
    "    # w_h2 : les poids du second hidden layer, shape [41 x 41]\n",
    "    # w_o  : les poids du layer d'output, shape [41 x 4]\n",
    "    # vérification : [n x 40] [40 x 41] [41 x 41] [41 x 4] = [n x 4]\n",
    "    # =====================================================================================================\n",
    "    \n",
    "    X = tf.nn.dropout(X, p_keep_input)\n",
    "    # --> dropout désactive certains neuronnes avec une certaine probabilité pour empêcher l'over-fitting\n",
    "    h1 = tf.nn.relu(tf.matmul(X, w_h1)) # relu ? Un type de neuronnes, mais pas tout compris.\n",
    "    h1 = tf.nn.dropout(h1, p_keep_hidden)\n",
    "    \n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w_h2))\n",
    "    h2 = tf.nn.dropout(h2, p_keep_hidden)\n",
    "\n",
    "    return tf.matmul(h2, w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date      Open      High       Low     Close      Volume  Adj Close\n",
      "0  2011-04-01  12321.02  12454.52  12301.11  12376.72  4223740000   12376.72\n",
      "1  2011-03-31  12350.84  12422.96  12277.05  12319.73  3566270000   12319.73\n",
      "2  2011-03-30  12280.07  12413.43  12271.52  12350.61  3809570000   12350.61\n",
      "3  2011-03-29  12193.87  12310.35  12141.65  12279.01  3482580000   12279.01\n",
      "4  2011-03-28  12221.19  12272.92  12197.88  12197.88  3215170000   12197.88\n"
     ]
    }
   ],
   "source": [
    "# Bon, ici, on charge les données qui vont nous servir pour les tests.\n",
    "# Quatre indices : Dow, Nasdaq, Rates, SNP500\n",
    "Dow = pandas.read_csv(\"dow.csv\", sep=\",\")\n",
    "print(Dow[:5]) # Donc le Dow ressemble à ça"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date     Open     High      Low    Close      Volume  Adj Close\n",
      "0  2011-04-01  2796.67  2802.63  2779.71  2789.60  2090120000    2789.60\n",
      "1  2011-03-31  2774.23  2783.98  2769.52  2781.07  1896420000    2781.07\n",
      "2  2011-03-30  2772.36  2779.95  2763.77  2776.79  1818410000    2776.79\n",
      "3  2011-03-29  2727.83  2756.89  2720.19  2756.89  1631160000    2756.89\n",
      "4  2011-03-28  2752.33  2754.63  2730.68  2730.68  1669260000    2730.68\n"
     ]
    }
   ],
   "source": [
    "Nasdaq = pandas.read_csv(\"nasdaq.csv\", sep=\",\")\n",
    "print(Nasdaq[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date     Open     High      Low    Close      Volume  Adj Close\n",
      "0  2011-04-01  1329.48  1337.85  1328.89  1332.41  4223740000    1332.41\n",
      "1  2011-03-31  1327.44  1329.77  1325.03  1325.83  3566270000    1325.83\n",
      "2  2011-03-30  1321.89  1331.74  1321.89  1328.26  3809570000    1328.26\n",
      "3  2011-03-29  1309.37  1319.45  1305.26  1319.44  3482580000    1319.44\n",
      "4  2011-03-28  1315.45  1319.74  1310.19  1310.19  2465820000    1310.19\n"
     ]
    }
   ],
   "source": [
    "SnP500 = pandas.read_csv(\"SP500.csv\", sep=\",\")\n",
    "print(SnP500[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date  prime\n",
      "0  1970-01   8.50\n",
      "1  1970-02   8.50\n",
      "2  1970-03   8.39\n",
      "3  1970-04   8.00\n",
      "4  1970-05   8.00\n"
     ]
    }
   ],
   "source": [
    "Rates = pandas.read_csv(\"rates.csv\", sep=\",\")\n",
    "print(Rates[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dow : 145033\n",
      "Nasdaq : 70917\n",
      "SnP500 : 107877\n",
      " Rates : 988\n"
     ]
    }
   ],
   "source": [
    "# On observe déjà quelques soucis au niveau de l'index Rates. Ensuite, les autres indexs sont de même formats\n",
    "# mais pas de même taille / avec les mêmes dates\n",
    "indexes = (\"Dow\", \"Nasdaq\", \"SnP500\", \"Rates\")\n",
    "for var in indexes:\n",
    "    print(\"{} : {}\".format(var.rjust(6), eval(var).size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'header'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-e8c37df06be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         ]\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'header'"
     ]
    }
   ],
   "source": [
    "# Pour gérer ça, on va créer une nouvelle table.\n",
    "# L'algorithme est simple : nous allons faire une intersection des données, pour ne pas avoir de jour présent\n",
    "# dans une base, mais pas dans l'autre.\n",
    "# A partir de là, il suffit de parcourir la base la moins fournie et de vérifier à chaque étape si la date\n",
    "# est présente dans les autres. Si oui, on rajoute l'entrée complètement renseignée\n",
    "\n",
    "# C'est le Nasdaq qui a le moins d'entrées.\n",
    "# Autre info : on garde seulement la valeur de close des indices complets\n",
    "datas = pandas.DataFrame(columns=['Date','Nasdaq', 'Dow', 'S&P500', 'Rates'])\n",
    "\n",
    "# Constructing the dates in reverse order (du coup, chronologique)\n",
    "for date in Nasdaq['Date'][::-1]:\n",
    "    if date in Dow['Date'].values and date in SnP500['Date'].values and date[:-3] in Rates['date'].values:\n",
    "        datas.loc[len(datas)] = [\n",
    "            date, \n",
    "            float(Dow.loc[Dow['Date'] == date, 'Close']),\n",
    "            float(Nasdaq.loc[Nasdaq['Date'] == date, 'Close']),\n",
    "            float(SnP500.loc[SnP500['Date'] == date, 'Close']),\n",
    "            float(Rates.loc[Rates['date'] == date[:-3], 'prime'])\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Nasdaq     Dow  S&P500  Rates\n",
      "0  1971-02-05  876.57  100.00   96.93   5.88\n",
      "1  1971-02-08  882.12  100.84   97.45   5.88\n",
      "2  1971-02-09  879.79  100.76   97.51   5.88\n",
      "3  1971-02-10  881.09  100.69   97.39   5.88\n",
      "4  1971-02-11  885.34  101.45   97.91   5.88\n"
     ]
    }
   ],
   "source": [
    "print(datas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Maintenant que c'est fait, on sauvegarde en csv\n",
    "datas.to_csv('datas.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Nasdaq     Dow  S&P500  Rates\n",
      "0  1971-02-05  876.57  100.00   96.93   5.88\n",
      "1  1971-02-08  882.12  100.84   97.45   5.88\n",
      "2  1971-02-09  879.79  100.76   97.51   5.88\n",
      "3  1971-02-10  881.09  100.69   97.39   5.88\n",
      "4  1971-02-11  885.34  101.45   97.91   5.88\n",
      "         Date    Nasdaq       Dow    S&P500     Rates\n",
      "0  1971-02-05  0.022004  0.009037  0.023056  0.152464\n",
      "1  1971-02-08  0.022413  0.009206  0.023402  0.152464\n",
      "2  1971-02-09  0.022241  0.009189  0.023442  0.152464\n",
      "3  1971-02-10  0.022337  0.009175  0.023362  0.152464\n",
      "4  1971-02-11  0.022650  0.009328  0.023708  0.152464\n"
     ]
    }
   ],
   "source": [
    "# Ici commence le traitement des données\n",
    "# Selon l'article que nous essayons de reproduire, nous allons appliquer une normalisation des données dans [0, 1]\n",
    "\n",
    "# La formule est la suivante : Index(x) = (Index(x) - Min(Index))/(Max(Index) - Min(Index))\n",
    "processed = pandas.read_csv(\"datas.csv\", sep=\",\")\n",
    "print(processed.head())\n",
    "\n",
    "for index in 'Nasdaq Dow S&P500 Rates'.split():\n",
    "    M = max(processed.loc[:, index])\n",
    "    m = min(processed.loc[:, index])\n",
    "    for i in range(len(processed)):\n",
    "        processed.loc[i, index] = (processed.loc[i, index] - m) / (M - m)\n",
    "print(processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# On sauvegarde les données <processed>\n",
    "processed.to_csv('processed.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ici on les re-charge, au cas où\n",
    "processed = pandas.read_csv(\"processed.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02264971  0.02290657  0.0229971   0.02283592  0.0226291   0.0221507\n",
      "  0.02144561  0.02152068  0.02193431  0.02240241  0.00932766  0.00944781\n",
      "  0.00947584  0.00938573  0.00932165  0.00917747  0.00897322  0.00898123\n",
      "  0.00916546  0.0092836   0.02370797  0.02405398  0.02420702  0.02390094\n",
      "  0.02347508  0.02292946  0.02225076  0.02249696  0.02292281  0.02307585\n",
      "  0.15246377  0.15246377  0.15246377  0.15246377  0.15246377  0.15246377\n",
      "  0.15246377  0.15246377  0.15246377  0.15246377]\n",
      "[ 0.02217057  0.00930563  0.02293612  0.15246377]\n"
     ]
    }
   ],
   "source": [
    "# Il reste encore quelques efforts sur les données\n",
    "# On va créer un objet sample, qui contient 11 jours.\n",
    "\n",
    "# La première nous fournira les 40 données d'input, dans une liste, sous cette forme :\n",
    "# [Dow[i:i+10] Nasdaq[i:i+10] S&P[i:i+10] Rates[i:i+10]]\n",
    "class Sample(object):\n",
    "    def __init__(self, i):\n",
    "        self.xdates = np.array(processed.loc[i:i+9, 'Date'])\n",
    "        self.x = np.concatenate((\n",
    "            np.array(processed.loc[i:i+9, 'Nasdaq']),\n",
    "            np.array(processed.loc[i:i+9, 'Dow']),\n",
    "            np.array(processed.loc[i:i+9, 'S&P500']),\n",
    "            np.array(processed.loc[i:i+9, 'Rates'])\n",
    "        ))\n",
    "        self.ydate = np.array(processed.loc[i+10, 'Date'])\n",
    "        self.y = np.array([\n",
    "            processed.loc[i+10, 'Nasdaq'],\n",
    "            processed.loc[i+10, 'Dow'],\n",
    "            processed.loc[i+10, 'S&P500'],\n",
    "            processed.loc[i+10, 'Rates']\n",
    "        ])\n",
    "    \n",
    "sample = Sample(4)\n",
    "print(sample.x)\n",
    "print(sample.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642 276\n"
     ]
    }
   ],
   "source": [
    "p_train = 0.7\n",
    "p_test = 1 - p_train\n",
    "n = len(processed.Date.values)//11\n",
    "samples = [\n",
    "    Sample(i*11) for i in range(n)\n",
    "]\n",
    "from random import sample\n",
    "indices = sample(samples, int(p_train*n))\n",
    "train = np.array(indices)\n",
    "test = []\n",
    "for i in range(n):\n",
    "    if samples[i] not in train:\n",
    "        test.append(samples[i])\n",
    "\n",
    "test = np.array(test)\n",
    "\n",
    "print(len(train), len(test))\n",
    "\n",
    "trX = np.array([tr.x for tr in train])\n",
    "trY = np.array([tr.y for tr in train])\n",
    "teX = np.array([te.x for te in test])\n",
    "teY = np.array([te.y for te in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rappel :\n",
    "# =====================================================================================================\n",
    "# X    : les inputs, shape [n x 40]\n",
    "# w_h1 : les poids du premier hidden layer, shape [40 x 41]\n",
    "# w_h2 : les poids du second hidden layer, shape [41 x 41]\n",
    "# w_o  : les poids du layer d'output, shape [41 x 4]\n",
    "# vérification : [n x 40] [40 x 41] [41 x 41] [41 x 4] = [n x 4]\n",
    "# =====================================================================================================\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 40])\n",
    "Y = tf.placeholder(\"float\", [None, 4])\n",
    "\n",
    "w_h = init_weights([40, 41])\n",
    "w_h2 = init_weights([41, 41])\n",
    "w_o = init_weights([41, 4])\n",
    "\n",
    "p_keep_input = tf.placeholder(\"float\")   # La probabilité qui peut changer\n",
    "p_keep_hidden = tf.placeholder(\"float\")  # La probabilité qui peut changer\n",
    "py_x = model(X, w_h, w_h2, w_o, p_keep_input, p_keep_hidden) # On construit le modèle avec X l'input externe\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y))\n",
    "train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost) # Ligne importante, tout se joue ici\n",
    "# On train avec un optimizer ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# Init variables\n",
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(20000):\n",
    "    for start, end in zip(range(0, len(trX), 10), range(10, len(trX)+1, 10)):\n",
    "        # batches of 10\n",
    "        sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end],\n",
    "                                          p_keep_input: 1.0, p_keep_hidden: 1.0})\n",
    "    if i % 200 == 0:\n",
    "        pass\n",
    "#         print(i, teY, sess.run(py_x, feed_dict={X: teX, Y: teY, p_keep_input: 1.0, p_keep_hidden: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02144561  0.00897322  0.02225076  0.15246377]\n",
      " [ 0.02647029  0.01110588  0.02684198  0.12811594]\n",
      " [ 0.02308174  0.01110788  0.02457964  0.1542029 ]\n",
      " [ 0.02278587  0.01084556  0.02399409  0.15942029]\n",
      " [ 0.02185777  0.0109597   0.02362812  0.15362319]] \n",
      " [[  1.18385623e+10   1.18384609e+10   1.18386002e+10   1.18389002e+10]\n",
      " [  8.33563689e+10   8.33563361e+10   8.33564180e+10   8.33565573e+10]\n",
      " [  2.93231288e+10   2.93230469e+10   2.93231800e+10   2.93234401e+10]\n",
      " [  1.43969690e+10   1.43968686e+10   1.43970140e+10   1.43973233e+10]\n",
      " [  2.31811523e+10   2.31810724e+10   2.31811953e+10   2.31814820e+10]]\n"
     ]
    }
   ],
   "source": [
    "print(teY[0:5], '\\n', sess.run(py_x, feed_dict={X: teX[0:5], Y: teY[0:5], p_keep_input: 1.0, p_keep_hidden: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02144561  0.00897322  0.02225076  0.15246377]\n",
      "Tensor(\"MatMul_2:0\", shape=(?, 4), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e783d14ce68c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mXv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mYv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_keep_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_keep_hidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mYs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mPs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "predicted = [None for i in range(10)]\n",
    "Ys = []\n",
    "Ps = []\n",
    "for i in range(len(processed.Date)-11):\n",
    "    Xv = np.concatenate((\n",
    "            np.array(processed.loc[i:i+9, 'Nasdaq']),\n",
    "            np.array(processed.loc[i:i+9, 'Dow']),\n",
    "            np.array(processed.loc[i:i+9, 'S&P500']),\n",
    "            np.array(processed.loc[i:i+9, 'Rates'])\n",
    "        ))\n",
    "    Yv = np.array([\n",
    "            processed.loc[i+10, 'Nasdaq'],\n",
    "            processed.loc[i+10, 'Dow'],\n",
    "            processed.loc[i+10, 'S&P500'],\n",
    "            processed.loc[i+10, 'Rates']\n",
    "        ])\n",
    "    print(Yv)\n",
    "    predict = sess.run(py_x, feed_dict={X: Xv, Y: Yv, p_keep_input: 1.0, p_keep_hidden: 1.0})\n",
    "    Ys.append(Yv)\n",
    "    Ps.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import dates\n",
    "from datetime import strptime\n",
    "\n",
    "dates = np.array([strptime(x) for x in processed.loc[10:,'Date']])\n",
    "dates = dates.datenum(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub1 = plt.subplot(221)\n",
    "sub1.plot_date(dates, X[:,1])\n",
    "sub1.plot_date(dates, Y[:,1])\n",
    "sub1.title(\"Subplot 1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
